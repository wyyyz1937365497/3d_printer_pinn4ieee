"""
MATLAB to Python Data Converter
================================

This script reads MATLAB .mat files generated by run_full_simulation.m
and converts them to Python-friendly formats (NumPy arrays, HDF5, or CSV).

Usage:
    python convert_matlab_to_python.py <mat_file> <output_format>

Output formats:
    - hdf5: HDF5 file (recommended, preserves structure)
    - npz: NumPy compressed archive
    - csv: Individual CSV files per variable
    - all: Generate all formats

Author: Generated for 3D Printer PINN Project
Date: 2026-01-27
"""

import os
import sys
import argparse
from pathlib import Path

import numpy as np
import h5py
import scipy.io as sio
import pandas as pd


def load_matlab_data(mat_file):
    """
    Load MATLAB .mat file and extract simulation_data structure.

    Parameters
    ----------
    mat_file : str
        Path to MATLAB .mat file

    Returns
    -------
    data : dict
        Dictionary containing all simulation variables
    """
    print(f"Loading MATLAB file: {mat_file}")

    # Load .mat file
    mat_data = sio.loadmat(mat_file)

    # Extract simulation_data structure
    if 'simulation_data' not in mat_data:
        raise ValueError("MATLAB file does not contain 'simulation_data' variable")

    sim_data_matlab = mat_data['simulation_data'][0, 0]

    # Convert MATLAB structure to Python dictionary
    data = {}
    field_names = sim_data_matlab.dtype.names

    print(f"Found {len(field_names)} variables:")
    for field in field_names:
        value = sim_data_matlab[field][0, 0]

        # Squeeze to remove singleton dimensions
        if isinstance(value, np.ndarray):
            value = value.squeeze()

        # Convert MATLAB logical to bool
        if value.dtype == np.object_ and len(value.shape) == 2 and value.shape[0] == 1:
            # This might be a string or other object
            pass
        elif value.dtype.name.startswith('uint') or value.dtype.name.startswith('int'):
            pass
        elif value.dtype.name == 'bool':
            value = value.astype(bool)

        data[field] = value
        print(f"  {field}: shape={value.shape}, dtype={value.dtype}")

    return data


def save_to_hdf5(data, output_file):
    """
    Save data to HDF5 format.

    HDF5 is recommended because:
    - Preserves data structure
    - Efficient compression
    - Fast random access
    - Compatible with most ML frameworks

    Parameters
    ----------
    data : dict
        Simulation data dictionary
    output_file : str
        Output HDF5 file path
    """
    print(f"\nSaving to HDF5: {output_file}")

    with h5py.File(output_file, 'w') as f:
        # Create metadata
        f.attrs['n_samples'] = len(data.get('time', []))
        f.attrs['n_variables'] = len(data)

        # Save each variable as a dataset
        for key, value in data.items():
            if isinstance(value, np.ndarray):
                # Handle numeric arrays
                if value.dtype.kind in ['i', 'u', 'f', 'b']:  # numeric or boolean
                    f.create_dataset(key, data=value, compression='gzip')
                else:
                    # Skip non-numeric arrays for now
                    print(f"  Skipping {key} (non-numeric)")
            elif isinstance(value, (int, float, bool)):
                f.create_dataset(key, data=value)
            else:
                print(f"  Skipping {key} (unsupported type)")

    print(f"  Saved {len(data)} variables to HDF5")


def save_to_npz(data, output_file):
    """
    Save data to NumPy compressed archive.

    Parameters
    ----------
    data : dict
        Simulation data dictionary
    output_file : str
        Output .npz file path
    """
    print(f"\nSaving to NPZ: {output_file}")

    # Filter to only numeric arrays
    npz_data = {k: v for k, v in data.items() if isinstance(v, np.ndarray)}

    np.savez_compressed(output_file, **npz_data)

    print(f"  Saved {len(npz_data)} variables to NPZ")


def save_to_csv(data, output_dir):
    """
    Save each variable to individual CSV files.

    Parameters
    ----------
    data : dict
        Simulation data dictionary
    output_dir : str
        Output directory for CSV files
    """
    print(f"\nSaving to CSV directory: {output_dir}")

    os.makedirs(output_dir, exist_ok=True)

    # Also save a combined CSV with time series data
    combined_data = {}

    for key, value in data.items():
        if isinstance(value, np.ndarray):
            # Only save 1D arrays
            if value.ndim == 1:
                combined_data[key] = value

                # Individual CSV
                csv_file = os.path.join(output_dir, f"{key}.csv")
                np.savetxt(csv_file, value, header=f"{key}", comments='')

    # Combined CSV
    combined_file = os.path.join(output_dir, "combined_data.csv")
    df = pd.DataFrame(combined_data)
    df.to_csv(combined_file, index=False)

    print(f"  Saved {len(combined_data)} variables to CSV")


def create_training_dataset(data, output_file):
    """
    Create a structured training dataset for PINN.

    This creates a HDF5 file with organized groups:
    /inputs    - Input features (G-code, kinematics)
    /states    - System states (forces, temperatures)
    /outputs   - Target outputs (errors, adhesion)
    /params    - Physical parameters

    Parameters
    ----------
    data : dict
        Simulation data dictionary
    output_file : str
        Output HDF5 file path
    """
    print(f"\nCreating training dataset: {output_file}")

    with h5py.File(output_file, 'w') as f:

        # === INPUTS (G-code and process parameters) ===
        inputs_group = f.create_group('inputs')

        # Time
        if 'time' in data:
            inputs_group.create_dataset('time', data=data['time'], compression='gzip')

        # Reference trajectory
        for var in ['x_ref', 'y_ref', 'z_ref']:
            if var in data:
                inputs_group.create_dataset(var, data=data[var], compression='gzip')

        # Reference kinematics
        for var in ['vx_ref', 'vy_ref', 'vz_ref', 'ax_ref', 'ay_ref', 'az_ref']:
            if var in data:
                inputs_group.create_dataset(var, data=data[var], compression='gzip')

        # G-code features
        for var in ['is_extruding', 'is_travel', 'is_corner', 'corner_angle',
                    'curvature', 'layer_num', 'dist_from_last_corner']:
            if var in data:
                inputs_group.create_dataset(var, data=data[var], compression='gzip')

        # === STATES (System dynamics and thermal) ===
        states_group = f.create_group('states')

        # Actual trajectory (after dynamics)
        for var in ['x_act', 'y_act', 'z_act', 'vx_act', 'vy_act', 'vz_act']:
            if var in data:
                states_group.create_dataset(var, data=data[var], compression='gzip')

        # Forces
        for var in ['F_inertia_x', 'F_inertia_y', 'F_elastic_x', 'F_elastic_y']:
            if var in data:
                states_group.create_dataset(var, data=data[var], compression='gzip')

        # Belt stretch
        for var in ['belt_stretch_x', 'belt_stretch_y']:
            if var in data:
                states_group.create_dataset(var, data=data[var], compression='gzip')

        # Thermal
        for var in ['T_nozzle', 'T_interface', 'T_surface', 'cooling_rate',
                    'temp_gradient_z', 'interlayer_time']:
            if var in data:
                states_group.create_dataset(var, data=data[var], compression='gzip')

        # === OUTPUTS (Target variables) ===
        outputs_group = f.create_group('outputs')

        # Trajectory error (vector!)
        for var in ['error_x', 'error_y', 'error_magnitude', 'error_direction']:
            if var in data:
                outputs_group.create_dataset(var, data=data[var], compression='gzip')

        # Adhesion strength
        if 'adhesion_ratio' in data:
            outputs_group.create_dataset('adhesion_ratio', data=data['adhesion_ratio'], compression='gzip')

        # Quality metrics (Implicit quality parameters)
        for var in ['internal_stress', 'porosity', 'dimensional_accuracy', 'quality_score']:
            if var in data:
                outputs_group.create_dataset(var, data=data[var], compression='gzip')
                print(f"  Added quality metric: {var}")

        # === METADATA ===
        # Save variable descriptions
        descriptions = {
            # Time
            'time': 'Time (s)',

            # Reference trajectory
            'x_ref': 'Reference X position (mm)',
            'y_ref': 'Reference Y position (mm)',
            'z_ref': 'Reference Z position (mm)',

            # Reference kinematics
            'vx_ref': 'Reference X velocity (mm/s)',
            'vy_ref': 'Reference Y velocity (mm/s)',
            'vz_ref': 'Reference Z velocity (mm/s)',
            'ax_ref': 'Reference X acceleration (mm/s²)',
            'ay_ref': 'Reference Y acceleration (mm/s²)',
            'az_ref': 'Reference Z acceleration (mm/s²)',

            # G-code features
            'is_extruding': 'Extruding flag (bool)',
            'is_travel': 'Travel move flag (bool)',
            'is_corner': 'Corner flag (bool)',
            'corner_angle': 'Corner angle (degrees)',
            'curvature': 'Path curvature (1/mm)',
            'layer_num': 'Layer number',
            'dist_from_last_corner': 'Distance from last corner (mm)',

            # Actual trajectory
            'x_act': 'Actual X position (mm)',
            'y_act': 'Actual Y position (mm)',
            'z_act': 'Actual Z position (mm)',
            'vx_act': 'Actual X velocity (mm/s)',
            'vy_act': 'Actual Y velocity (mm/s)',
            'vz_act': 'Actual Z velocity (mm/s)',

            # Forces
            'F_inertia_x': 'Inertial force X (N)',
            'F_inertia_y': 'Inertial force Y (N)',
            'F_elastic_x': 'Elastic force X (N)',
            'F_elastic_y': 'Elastic force Y (N)',

            # Belt stretch
            'belt_stretch_x': 'Belt stretch X (mm)',
            'belt_stretch_y': 'Belt stretch Y (mm)',

            # Thermal
            'T_nozzle': 'Nozzle temperature (°C)',
            'T_interface': 'Layer interface temperature (°C)',
            'T_surface': 'Surface temperature (°C)',
            'cooling_rate': 'Cooling rate (°C/s)',
            'temp_gradient_z': 'Vertical temperature gradient (°C/mm)',
            'interlayer_time': 'Time between layers (s)',

            # Outputs
            'error_x': 'Position error X component (mm)',
            'error_y': 'Position error Y component (mm)',
            'error_magnitude': 'Position error magnitude (mm)',
            'error_direction': 'Position error direction (rad)',
            'adhesion_ratio': 'Interlayer adhesion ratio (0-1)',
            'internal_stress': 'Internal residual stress (MPa)',
            'porosity': 'Porosity percentage (0-100%)',
            'dimensional_accuracy': 'Dimensional accuracy error (mm)',
            'quality_score': 'Overall quality score (0-1)',
        }

        desc_group = f.create_group('descriptions')
        for key, desc in descriptions.items():
            if key in data:
                desc_group.create_dataset(key, data=np.string_(desc))

    print(f"  Training dataset created with {len(inputs_group)} inputs, "
          f"{len(states_group)} states, {len(outputs_group)} outputs")


def main():
    parser = argparse.ArgumentParser(description='Convert MATLAB simulation data to Python formats')
    parser.add_argument('mat_file', type=str, help='Path to MATLAB .mat file')
    parser.add_argument('format', type=str, choices=['hdf5', 'npz', 'csv', 'training', 'all'],
                        help='Output format')
    parser.add_argument('--output', '-o', type=str, help='Output file/directory path')

    args = parser.parse_args()

    # Check if input file exists
    if not os.path.exists(args.mat_file):
        print(f"Error: File not found: {args.mat_file}")
        sys.exit(1)

    # Load MATLAB data
    data = load_matlab_data(args.mat_file)

    # Determine output path
    if args.output:
        output_path = args.output
    else:
        # Use input filename with different extension
        base_path = Path(args.mat_file).stem
        output_path = str(base_path)

    # Save in requested format(s)
    if args.format == 'all':
        save_to_hdf5(data, f"{output_path}.h5")
        save_to_npz(data, f"{output_path}.npz")
        save_to_csv(data, f"{output_path}_csv")
        create_training_dataset(data, f"{output_path}_training.h5")

    elif args.format == 'hdf5':
        save_to_hdf5(data, f"{output_path}.h5")

    elif args.format == 'npz':
        save_to_npz(data, f"{output_path}.npz")

    elif args.format == 'csv':
        save_to_csv(data, output_path)

    elif args.format == 'training':
        create_training_dataset(data, f"{output_path}.h5")

    print("\nConversion complete!")


if __name__ == '__main__':
    main()
