#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†ç»Ÿè®¡è„šæœ¬
ç»Ÿè®¡å½“å‰å·²æ”¶é›†çš„ä»¿çœŸæ•°æ®é‡å’Œè®­ç»ƒæ ·æœ¬æ•°
"""

import os
import glob
import numpy as np
from pathlib import Path

def count_mat_files():
    """ç»Ÿè®¡.matæ–‡ä»¶"""
    print("=" * 80)
    print("æ•°æ®æ–‡ä»¶ç»Ÿè®¡")
    print("=" * 80)
    print()

    # æŸ¥æ‰¾æ‰€æœ‰æ•°æ®ç›®å½•
    data_dirs = glob.glob("data_simulation_*")
    data_dirs.sort()

    if not data_dirs:
        print("[!] æœªæ‰¾åˆ°ä»»ä½•æ•°æ®ç›®å½•")
        return

    total_files = 0
    total_size_mb = 0

    print(f"{'ç›®å½•':<60} {'æ–‡ä»¶æ•°':>10} {'å¤§å°(MB)':>12}")
    print("-" * 85)

    for data_dir in data_dirs:
        mat_files = glob.glob(os.path.join(data_dir, "*.mat"))
        n_files = len(mat_files)

        # è®¡ç®—ç›®å½•å¤§å°
        dir_size = 0
        for mat_file in mat_files:
            if os.path.exists(mat_file):
                dir_size += os.path.getsize(mat_file) / (1024 * 1024)

        total_files += n_files
        total_size_mb += dir_size

        dir_name = os.path.basename(data_dir)
        print(f"{dir_name:<60} {n_files:>10} {dir_size:>11.1f}")

    print("-" * 85)
    print(f"{'æ€»è®¡':<60} {total_files:>10} {total_size_mb:>11.1f}")
    print()

    return total_files, data_dirs

def estimate_training_samples(total_files):
    """ä¼°ç®—è®­ç»ƒæ ·æœ¬æ•°"""
    print("=" * 80)
    print("è®­ç»ƒæ ·æœ¬ä¼°ç®—")
    print("=" * 80)
    print()

    # å‡è®¾æ¯ä¸ªæ–‡ä»¶å¹³å‡ç‚¹æ•°ï¼ˆæ ¹æ®ä¸åŒgcodeç±»å‹ï¼‰
    avg_points_per_layer = {
        '3DBenchy': 1200,
        'bearing': 1000,
        'Nautilus': 2000,
        'boat': 1200,
    }

    # æ ¹æ®æ–‡ä»¶ååˆ¤æ–­ç±»å‹
    def get_avg_points(dirname):
        for key, val in avg_points_per_layer.items():
            if key in dirname:
                return val
        return 1200  # é»˜è®¤å€¼

    # è®¡ç®—æ€»æ•°æ®ç‚¹
    data_dirs = glob.glob("data_simulation_*")
    total_points = 0
    for data_dir in data_dirs:
        mat_files = glob.glob(os.path.join(data_dir, "*.mat"))
        n_files = len(mat_files)
        avg_points = get_avg_points(os.path.basename(data_dir))
        total_points += n_files * avg_points

    print(f"é…ç½®å‚æ•°:")
    print(f"  åºåˆ—é•¿åº¦ (seq_len): 200")
    print(f"  é¢„æµ‹é•¿åº¦ (pred_len): 50")
    print(f"  é‡‡æ ·é—´éš” (stride): 5")
    print()

    # ä¼°ç®—è®­ç»ƒæ ·æœ¬æ•°
    # æ¯ä¸ªåºåˆ—éœ€è¦ seq_len + pred_len ä¸ªç‚¹ï¼Œåºåˆ—ä¹‹é—´strideé—´éš”
    stride = 5
    seq_len = 200
    pred_len = 50

    # ç²—ç•¥ä¼°ç®—ï¼šæ¯ä¸ªåŸå§‹ç‚¹çº¦ç”Ÿæˆ 1/stride ä¸ªæ ·æœ¬
    estimated_samples = total_points // stride

    print(f"åŸå§‹æ•°æ®ç‚¹: ~{total_points:,}")
    print(f"è®­ç»ƒæ ·æœ¬æ•° (stride={stride}): ~{estimated_samples:,}")
    print()

    # æ¨¡å‹å‚æ•°ç»Ÿè®¡
    model_params = 896030
    ratio = model_params / estimated_samples if estimated_samples > 0 else float('inf')

    print(f"æ¨¡å‹å‚æ•°: {model_params:,}")
    print(f"å‚æ•°/æ ·æœ¬æ¯”: {ratio:.1f}:1", end="")

    if ratio < 10:
        print(" âœ…âœ… (ä¼˜ç§€ï¼)")
    elif ratio < 20:
        print(" âœ… (è‰¯å¥½)")
    elif ratio < 50:
        print(" âš ï¸ (å¯æ¥å—)")
    else:
        print(" âŒ (ä¸è¶³)")

    print()

    # ç›®æ ‡æ ·æœ¬æ•°ï¼ˆæŒ‰ç…§è®ºæ–‡çº§åˆ« 20:1 æ¯”ä¾‹ï¼‰
    target_ratio = 20
    target_samples = model_params / target_ratio

    print(f"ç›®æ ‡æ ·æœ¬æ•° (20:1æ¯”ä¾‹): ~{target_samples:,.0f}")
    if estimated_samples < target_samples:
        shortage = target_samples - estimated_samples
        shortage_pct = (shortage / target_samples) * 100
        print(f"è¿˜éœ€æ”¶é›†: ~{shortage:,.0f} æ ·æœ¬ (çŸ­ç¼º {shortage_pct:.1f}%)")
    else:
        print(f"âœ… å·²è¾¾åˆ°ç›®æ ‡ï¼")

    print()

    return estimated_samples

def check_per_directory():
    """è¯¦ç»†ç»Ÿè®¡æ¯ä¸ªç›®å½•"""
    print("=" * 80)
    print("å„ç›®å½•è¯¦ç»†ç»Ÿè®¡")
    print("=" * 80)
    print()

    data_dirs = glob.glob("data_simulation_*")
    data_dirs.sort()

    print(f"{'ç›®å½•':<55} {'å±‚æ•°':>8} {'é¢„æœŸç‚¹æ•°':>12} {'é¢„æœŸæ ·æœ¬':>12}")
    print("-" * 90)

    total_expected_points = 0
    total_expected_samples = 0

    for data_dir in data_dirs:
        mat_files = glob.glob(os.path.join(data_dir, "*.mat"))
        n_layers = len(mat_files)

        # æ ¹æ®ç›®å½•åä¼°ç®—ç‚¹æ•°/å±‚
        dir_name = os.path.basename(data_dir)
        if 'Benchy' in dir_name or 'boat' in dir_name:
            points_per_layer = 1200
        elif 'bearing' in dir_name:
            points_per_layer = 1000
        elif 'Nautilus' in dir_name:
            points_per_layer = 2000
        else:
            points_per_layer = 1200

        expected_points = n_layers * points_per_layer
        expected_samples = expected_points // 5

        total_expected_points += expected_points
        total_expected_samples += expected_samples

        # ç®€åŒ–ç›®å½•åæ˜¾ç¤º
        if len(dir_name) > 53:
            dir_display = "..." + dir_name[-50:]
        else:
            dir_display = dir_name

        print(f"{dir_display:<55} {n_layers:>8} {expected_points:>12,} {expected_samples:>12,}")

    print("-" * 90)
    print(f"{'æ€»è®¡':<55} {'':>8} {total_expected_points:>12,} {total_expected_samples:>12,}")
    print()

def show_progress():
    """æ˜¾ç¤ºæ”¶é›†è¿›åº¦"""
    print("=" * 80)
    print("æ•°æ®æ”¶é›†è¿›åº¦")
    print("=" * 80)
    print()

    # ç›®æ ‡é…ç½®ï¼ˆåŸºäºcollect_data_single_param.mï¼‰
    targets = {
        '3DBenchy': 48,
        'bearing': 75,
        'Nautilus': 56,
        'boat': 74,
    }

    data_dirs = glob.glob("data_simulation_*")
    total_completed = 0
    total_target = 0

    print(f"{'æ–‡ä»¶':<20} {'ç›®æ ‡':>10} {'å·²å®Œæˆ':>10} {'è¿›åº¦':>10} {'çŠ¶æ€':>10}")
    print("-" * 65)

    for name, target in targets.items():
        # æŸ¥æ‰¾å¯¹åº”ç›®å½•
        matching_dirs = [d for d in data_dirs if name in d]

        if matching_dirs:
            data_dir = matching_dirs[0]
            mat_files = glob.glob(os.path.join(data_dir, "*.mat"))
            completed = len(mat_files)
        else:
            completed = 0

        total_completed += completed
        total_target += target

        progress = (completed / target * 100) if target > 0 else 0

        if progress >= 100:
            status = "âœ…"
        elif progress > 0:
            status = "ğŸ”„"
        else:
            status = "â³"

        print(f"{name:<20} {target:>10} {completed:>10} {progress:>9.1f}% {status:>10}")

    print("-" * 65)
    overall_progress = (total_completed / total_target * 100) if total_target > 0 else 0
    print(f"{'æ€»è®¡':<20} {total_target:>10} {total_completed:>10} {overall_progress:>9.1f}%")
    print()

    return total_completed, total_target

def main():
    print()
    print("â•”" + "=" * 78 + "â•—")
    print("â•‘" + " " * 20 + "3Dæ‰“å°PINNæ•°æ®é›†ç»Ÿè®¡å·¥å…·" + " " * 32 + "â•‘")
    print("â•š" + "=" * 78 + "â•")
    print()

    # 1. ç»Ÿè®¡.matæ–‡ä»¶
    total_files, data_dirs = count_mat_files()

    if total_files == 0:
        print("[!] æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
        return

    # 2. æ˜¾ç¤ºæ”¶é›†è¿›åº¦
    show_progress()

    # 3. ä¼°ç®—è®­ç»ƒæ ·æœ¬
    estimate_training_samples(total_files)

    # 4. è¯¦ç»†ç›®å½•ç»Ÿè®¡
    check_per_directory()

    print("=" * 80)
    print("ä¸‹ä¸€æ­¥å»ºè®®:")
    print("=" * 80)
    print()
    print("1. éªŒè¯æ•°æ®åŠ è½½:")
    print('   python -c "from data.simulation import PrinterSimulationDataset; import glob;')
    print('                files = glob.glob(\'data_simulation_*/*.mat\');')
    print('                print(f\'æ‰¾åˆ° {len(files)} ä¸ª.matæ–‡ä»¶\');')
    print('                ds = PrinterSimulationDataset(files, seq_len=200, pred_len=50,')
    print('                                          stride=5, mode=\'train\', fit_scaler=True);')
    print('                print(f\'è®­ç»ƒæ ·æœ¬: {len(ds)}\')"')
    print()
    print("2. å¼€å§‹è®­ç»ƒæ¨¡å‹:")
    print('   python experiments/train_implicit_state_tcn_optimized.py \\')
    print('       --data_dir "data_simulation_*" \\')
    print('       --epochs 100 \\')
    print('       --batch_size 256 \\')
    print('       --lr 1e-3 \\')
    print('       --lambda_physics 0.05 \\')
    print('       --num_workers 8')
    print()
    print("=" * 80)
    print()

if __name__ == "__main__":
    main()
